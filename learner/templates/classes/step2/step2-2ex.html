{% load static %}
<!DOCTYPE html>
<html>
  <head>
    <title>Online Machine Learning Class</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!--css tags-->
    <link rel="stylesheet" href="{% static 'css/cssReset.css' %}?{% now 'U' %}" />
    <link rel="stylesheet" href="{% static 'css/practice.css' %}?{% now 'U' %}" />
    <link rel="stylesheet" href="{% static 'codemirror-5.65.3/lib/codemirror.css' %}?{% now 'U' %}" />
    <link rel="stylesheet" href="{% static 'codemirror-5.65.3/theme/dracula.css' %}?{% now 'U' %}" />
    <!--JS TAGAS-->
    <script type="text/javascript" src="{% static 'codemirror-5.65.3/mode/css/css.js' %}?{% now 'U' %}"></script>
    <script type="text/javascript" src="{% static 'codemirror-5.65.3/lib/codemirror.js' %}?{% now 'U' %}"></script>
    <script type="text/javascript" src="{% static 'codemirror-5.65.3/mode/python/python.js' %}?{% now 'U' %}"></script>
  </head>
  <body>
    <!--내비게이션 있음-->
    {% include "../navigation.html" %}


    <!--컨텐트-->
    <div class="container">
      {% include "../sidebar.html" %}


      <div class="class-content">
        <h2>Understanding of Tensor</h2>
      <h3>Example</h3>
      <p>위에서 배운 Hypothesis(직선의 방정식), Cost(비용 함수)를 이용해 경사 하강법을 구현해봅시다. 
        lr은 학습률(learning rate)를 의미합니다. optimizer.zero_grad()를 실행하게 되면 미분을 통해 얻은 기울기를 0으로 초기화합니다. 
        기울기를 초기화해야만 새로운 가중치 편향에 대해서 새로운 기울기를 구할 수 있습니다. 
        그 다음 cost.backward() 함수를 호출하면 가중치 W와 편향 b에 대한 기울기가 계산됩니다. 
        그 다음 경사 하강법 최적화 함수 optimizer의 .step() 함수를 호출하여 인수로 들어갔던 W와 b에서 리턴되는 변수들의 기울기에 학습률(learining rate) 0.01을 곱하여 빼줌으로써 업데이트합니다. 
        아래와 같이 작성해봅시다.</p>
      <!--입력 코드-->
      <h4>Input</h4>
      <textarea id="inputeditor">
import torch

#주석처리부분이 사용자가 구현해야 할 부분
def example2_2():

    # 데이터
    x_train = torch.FloatTensor([[1], [2], [3]])
    y_train = torch.FloatTensor([[2], [4], [6]])
    # # 모델 초기화
    # W = torch.zeros(1, requires_grad=True)
    # b = torch.zeros(1, requires_grad=True)
    # # optimizer 설정
    # optimizer = torch.optim.SGD([W, b], lr=0.01)

    # nb_epochs = 2000 # 원하는만큼 경사 하강법을 반복
    # for epoch in range(nb_epochs + 1):

    #     # H(x) 계산
    #     hypothesis = x_train * W + b

    #     # cost 계산
    #     cost = torch.mean((hypothesis - y_train) ** 2)

    #     # cost로 H(x) 개선
    #     optimizer.zero_grad()
    #     cost.backward()
    #     optimizer.step()

    #     # 100번마다 로그 출력
    #     if epoch % 100 == 0:
    #         print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(
    #             epoch, nb_epochs, W.item(), b.item(), cost.item()))
    
    return hypothesis, cost, W, b

def judge_2_2ex(cost,W,b):
    if(cost.item()<0.1):
        pass
    else:
        return False
    if(0<b<0.1)&(1.95<W<2.05):
        return True
    else:
        return False

if __name__=="__main__":
    hypothesis, cost, W, b = example2_2()
    #사용자가 봐야할 Regression의 결과
    print(hypothesis)
    print(cost)
    print(W)
    print(b)

    print(judge_2_2ex(cost,W,b))
      </textarea>

      <!--출력 코드-->
      <h4>Output</h4>
      <textarea id="outputeditor">
Epoch    0/2000 W: 0.187, b: 0.080 Cost: 18.666666
Epoch  100/2000 W: 1.746, b: 0.578 Cost: 0.048171
Epoch  200/2000 W: 1.800, b: 0.454 Cost: 0.029767
Epoch  300/2000 W: 1.843, b: 0.357 Cost: 0.018394
Epoch  400/2000 W: 1.876, b: 0.281 Cost: 0.011366
Epoch  500/2000 W: 1.903, b: 0.221 Cost: 0.007024
Epoch  600/2000 W: 1.924, b: 0.174 Cost: 0.004340
Epoch  700/2000 W: 1.940, b: 0.136 Cost: 0.002682
Epoch  800/2000 W: 1.953, b: 0.107 Cost: 0.001657
Epoch  900/2000 W: 1.963, b: 0.084 Cost: 0.001024
Epoch 1000/2000 W: 1.971, b: 0.066 Cost: 0.000633
Epoch 1100/2000 W: 1.977, b: 0.052 Cost: 0.000391
Epoch 1200/2000 W: 1.982, b: 0.041 Cost: 0.000242
Epoch 1300/2000 W: 1.986, b: 0.032 Cost: 0.000149
Epoch 1400/2000 W: 1.989, b: 0.025 Cost: 0.000092
Epoch 1500/2000 W: 1.991, b: 0.020 Cost: 0.000057
Epoch 1600/2000 W: 1.993, b: 0.016 Cost: 0.000035
Epoch 1700/2000 W: 1.995, b: 0.012 Cost: 0.000022
Epoch 1800/2000 W: 1.996, b: 0.010 Cost: 0.000013
Epoch 1900/2000 W: 1.997, b: 0.008 Cost: 0.000008
Epoch 2000/2000 W: 1.997, b: 0.006 Cost: 0.000005                   
      </textarea>

      <br/>
      <a href="./step2-2" class="previous">&laquo; 전 수업</a>
      <a href="./step2-2pr" class="next">다음 수업 &raquo;</a>
    </div>

    <script>
      var editor = CodeMirror.fromTextArea(document.getElementById("inputeditor"),{
        mode:"python", 
        theme:"dracula", 
        lineNumbers: true,
        readOnly: true
      }).setSize("100%","1100");

      var editor = CodeMirror.fromTextArea(document.getElementById("outputeditor"),{
        mode:"python", 
        theme:"dracula", 
        lineNumbers: true,
        readOnly: true
      }).setSize("100%","440");
    </script>
      </div>

      <script>
        var dropdown = document.getElementsByClassName("dropdown-btn");
        var i;
  
        for (i = 0; i < dropdown.length; i++) {
          dropdown[i].addEventListener("click", function() {
            this.classList.toggle("clicked");
            var dropdownContent = this.nextElementSibling;
            if (dropdownContent.style.display === "block") {
              dropdownContent.style.display = "none";
            } else {
              dropdownContent.style.display = "block";
            }
          });
        }
      </script>
  </body>
</html>
